# -*- coding: utf-8 -*-
"""MLT-akhir-recomendation-content-filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B3dFaVBejsXWpbc8VRoHzNshvh6QE_Xo

# Data Understanding

## Impor modul
"""

import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""Mengimpor pustaka untuk manipulasi data:
pandas digunakan untuk membaca dan mengolah dataset, sedangkan numpy digunakan untuk operasi numerik seperti perhitungan matriks.
TfidfVectorizer untuk mengubah teks deskripsi menjadi representasi numerik berbobot menggunakan metode TF-IDF
cosine_similarity untuk menghitung kesamaan antar vektor, digunakan untuk mengukur kemiripan antara pengguna atau tempat wisata.

## Download dulu dataset dengan kode berikut.
"""

!pip install kaggle

from google.colab import files
files.upload()

import os
os.environ['KAGGLE_CONFIG_DIR'] = '/content'

!kaggle datasets download -d aprabowo/indonesia-tourism-destination

"""Blok kode ini digunakan untuk mengunduh dataset dari Kaggle ke Google Colab. Pertama, **`!pip install kaggle`** menginstal pustaka Kaggle. Kemudian, **`files.upload()`** memungkinkan Anda mengunggah file `kaggle.json` (API Key Kaggle) untuk autentikasi. Variabel lingkungan **`os.environ['KAGGLE_CONFIG_DIR']`** mengatur lokasi file konfigurasi Kaggle. Terakhir, **`!kaggle datasets download`** mengunduh dataset dari URL Kaggle yang ditentukan."""

!unzip indonesia-tourism-destination.zip

"""Perintah !unzip indonesia-tourism-destination.zip digunakan untuk mengekstrak file zip yang berisi dataset Indonesia Tourism Destination yang telah diunduh. File zip tersebut akan diekstrak ke dalam direktori saat ini di Google Colab, sehingga Anda dapat mengakses data yang ada di dalamnya untuk diproses lebih lanjut.

## # Membaca dataset
"""

package_tourism = pd.read_csv('/content/package_tourism.csv')
tourism_rating = pd.read_csv('/content/tourism_rating.csv')
tourism_with_id = pd.read_csv('/content/tourism_with_id.csv')
user = pd.read_csv('/content/user.csv')

"""Blok kode ini digunakan untuk membaca file CSV yang telah diekstrak dan memuatnya ke dalam variabel menggunakan pandas.read_csv(). Setiap file yang dibaca akan disimpan sebagai DataFrame, yang memungkinkan Anda untuk mengolah dan menganalisis data lebih lanjut.

## Menampilkan jumlah data unik di setiap dataset
"""

print('Jumlah data paket wisata: ', len(package_tourism['Package'].unique()))
print('Jumlah data rating wisata: ', len(tourism_rating['Place_Ratings'].unique()))
print('Jumlah data destinasi wisata dengan ID: ', len(tourism_with_id['Place_Id'].unique()))
print('Jumlah data pengguna: ', len(user['User_Id'].unique()))

"""Blok kode ini digunakan untuk menampilkan jumlah data unik dari masing-masing kolom yang relevan dalam dataset.

# Univariate Exploratory Data Analysis

## Package Tourism Variabel
"""

package_tourism.info()

"""Kode `package_tourism.info()` digunakan untuk menampilkan informasi ringkas tentang dataset `package_tourism`, yang meliputi jumlah kolom, tipe data, jumlah nilai non-null (data yang tidak kosong), dan tipe data untuk setiap kolom.

**Hasilnya** adalah sebagai berikut:

- **Package**: Tipe data `int64` dengan 100 nilai non-null, artinya semua 100 baris memiliki data yang valid.
- **City**: Tipe data `object` (biasanya string) dengan 100 nilai non-null, artinya kolom ini lengkap.
- **Place_Tourism1**: Tipe data `object` dengan 100 nilai non-null, semua data ada.
- **Place_Tourism2**: Tipe data `object` dengan 100 nilai non-null, lengkap.
- **Place_Tourism3**: Tipe data `object` dengan 100 nilai non-null, lengkap.
- **Place_Tourism4**: Tipe data `object` dengan 66 nilai non-null, artinya ada 34 nilai yang hilang (NaN).
- **Place_Tourism5**: Tipe data `object` dengan 39 nilai non-null, artinya ada 61 nilai yang hilang (NaN).

Secara keseluruhan, kolom `Place_Tourism4` dan `Place_Tourism5` memiliki nilai yang hilang (NaN), sedangkan kolom lainnya lengkap dengan data.
"""

package_tourism.head()

print('Banyak data: ', len(package_tourism.Package.unique()))
print('Kota: ', package_tourism.City.unique())
print('Destinasi 1: ', package_tourism.Place_Tourism1.unique())
print('Destinasi 2: ', package_tourism.Place_Tourism2.unique())
print('Destinasi 3: ', package_tourism.Place_Tourism3.unique())
print('Destinasi 4: ', package_tourism.Place_Tourism4.unique())

"""Berikut adalah hasil output untuk masing-masing kolom yang kamu tampilkan pada data `package_tourism`:

1. **Banyak data**: Terdapat 100 data unik pada kolom `Package`.
2. **Kota**: Ada 5 kota yang tercatat dalam data, yaitu:
   - Jakarta
   - Yogyakarta
   - Bandung
   - Semarang
   - Surabaya
3. **Destinasi 1**: Ini adalah daftar tempat wisata yang tercatat di kolom `Place_Tourism1`, antara lain:
   - Pasar Tanah Abang
   - Perpustakaan Nasional
   - Pulau Tidung
   - Museum Satria Mandala
   - Waterboom PIK (Pantai Indah Kapuk)
   - Alive Museum Ancol
   - dan lain-lain.
4. **Destinasi 2**: Ini adalah daftar tempat wisata yang tercatat di kolom `Place_Tourism2`, antara lain:
   - Taman Ayodya
   - Pasar Taman Puring
   - Monas
   - Pulau Bidadari
   - Museum Wayang
   - dan lain-lain.
5. **Destinasi 3**: Ini adalah daftar tempat wisata yang tercatat di kolom `Place_Tourism3`, antara lain:
   - Museum Tekstil
   - Pasar Petak Sembilan
   - Masjid Istiqlal
   - Pulau Pari
   - Museum Bahari Jakarta
   - SnowBay Waterpark
   - dan lain-lain.
6. **Destinasi 4**: Ini adalah daftar tempat wisata yang tercatat di kolom `Place_Tourism4`, antara lain:
   - Pulau Pramuka
   - Museum Macan (Modern and Contemporary Art in Nusantara)
   - Perpustakaan Nasional
   - Museum Fatahillah
   - Wisata Kuliner Pecenongan
   - Pasar Petak Sembilan
   - dan lain-lain.

## Tourism Rating Variabel
"""

tourism_rating.info()

"""Berdasarkan hasil dari fungsi `info()` yang kamu tampilkan untuk DataFrame `tourism_rating`, berikut adalah informasi tentang struktur data tersebut:

1. **Jumlah entri**: Terdapat 10.000 baris data, dengan indeks mulai dari 0 hingga 9999.
2. **Kolom**:
   - **User_Id**: Tipe data adalah `int64`, dengan 10.000 nilai non-null.
   - **Place_Id**: Tipe data adalah `int64`, dengan 10.000 nilai non-null.
   - **Place_Ratings**: Tipe data adalah `int64`, dengan 10.000 nilai non-null.
3. **Tipe Data**: Semua kolom bertipe data `int64`.
4. **Penggunaan Memori**: Memori yang digunakan oleh DataFrame ini adalah sekitar 234.5 KB.


"""

tourism_rating.head()

print('Banyak tourist: ', len(tourism_rating.User_Id.unique()))
print('Tempat: ', len(tourism_rating.Place_Id.unique()))
print('Rating: ', len(tourism_rating.Place_Ratings.unique()))

"""Berdasarkan hasil yang kamu dapatkan dari kode yang dieksekusi, berikut adalah penjelasan dari setiap output:

1. **Banyak tourist: 300**  
   Artinya ada 300 wisatawan (user) unik yang memberikan rating dalam dataset ini. Nilai ini diperoleh dari menghitung jumlah ID unik dalam kolom `User_Id`.

2. **Tempat: 437**  
   Ini menunjukkan bahwa ada 437 tempat yang telah mendapatkan rating dari para wisatawan. Nilai ini diperoleh dengan menghitung jumlah ID tempat unik dalam kolom `Place_Id`.

3. **Rating: 5**  
   Hasil ini menunjukkan bahwa rating yang diberikan oleh para wisatawan hanya mencakup 5 nilai unik, yang berarti sistem rating pada dataset ini mungkin menggunakan skala dari 1 hingga 5. Jadi, wisatawan hanya memberikan rating dalam rentang ini.

### Tourism With Id Variabel
"""

tourism_with_id.info()

"""Berdasarkan hasil yang diberikan, berikut adalah penjelasan dari dataset `tourism_with_id`:

### Kolom dan Tipe Data:
1. **Place_Id**: 437 entri, bertipe `int64`. Kolom ini menyimpan ID unik untuk setiap tempat.
2. **Place_Name**: 437 entri, bertipe `object`. Nama tempat wisata.
3. **Description**: 437 entri, bertipe `object`. Deskripsi mengenai tempat wisata tersebut.
4. **Category**: 437 entri, bertipe `object`. Kategori tempat wisata, seperti alam, budaya, dll.
5. **City**: 437 entri, bertipe `object`. Kota tempat tempat wisata tersebut berada.
6. **Price**: 437 entri, bertipe `int64`. Harga untuk mengunjungi tempat wisata (mungkin tiket masuk).
7. **Rating**: 437 entri, bertipe `float64`. Rating tempat wisata yang diberikan oleh pengunjung.
8. **Time_Minutes**: 205 entri, bertipe `float64`. Waktu yang dibutuhkan untuk mengunjungi tempat wisata (dalam menit). Hanya 205 entri yang memiliki nilai di kolom ini, artinya banyak data yang hilang atau tidak tersedia.
9. **Coordinate**: 437 entri, bertipe `object`. Koordinat geografis tempat wisata tersebut.
10. **Lat**: 437 entri, bertipe `float64`. Latitude (garis lintang) untuk koordinat tempat wisata.
11. **Long**: 437 entri, bertipe `float64`. Longitude (garis bujur) untuk koordinat tempat wisata.
12. **Unnamed: 11**: 0 entri, bertipe `float64`. Kolom ini tidak memiliki data sama sekali (semua nilai null).
13. **Unnamed: 12**: 437 entri, bertipe `int64`. Kolom ini tampaknya tidak memiliki nama yang jelas, mungkin kolom yang tidak terpakai atau tidak relevan.

### Menghapus Kolom yang Tidak Berguna
"""

tourism_with_id = tourism_with_id.drop(columns=['Unnamed: 11', 'Unnamed: 12'])
tourism_with_id.info()

"""Unnamed 11 dan 12 sudah dihilangkan

### Mengatasi Nilai Null pada Time_Minutes
"""

# Mengisi nilai null pada Time_Minutes dengan median
median_time = tourism_with_id['Time_Minutes'].median()
tourism_with_id['Time_Minutes'] = tourism_with_id['Time_Minutes'].fillna(median_time)

# Memeriksa kembali data setelah pengisian
tourism_with_id.info()

tourism_with_id.head()

"""## User"""

user.info()

"""Dataset ini terdiri dari 300 entri dengan tiga kolom: `User_Id`, `Location`, dan `Age`. Setiap kolom tidak memiliki nilai yang hilang (Non-Null Count = 300) dan terdiri dari data yang konsisten, yaitu `User_Id` sebagai ID unik pengguna dengan tipe integer, `Location` berisi nama lokasi pengguna dalam format string, dan `Age` yang menunjukkan usia pengguna dalam tipe integer. Semua data tampaknya bersih dari missing values dan tidak ada duplikasi yang terdeteksi. Namun, perlu diperiksa lebih lanjut untuk memastikan konsistensi penulisan lokasi dan kevalidan nilai usia."""

user.head()

print('Location: ', user.Location.unique())
print('Age: ', user.Age.unique())

"""Berdasarkan hasil tersebut, kolom `Location` berisi daftar nama tempat yang tersebar di berbagai daerah di Indonesia, seperti Semarang, Jakarta, Surabaya, Yogyakarta, dan lain-lain, dengan beberapa lokasi di Jawa Barat dan DKI Jakarta yang lebih banyak muncul. Kolom `Age` menunjukkan rentang usia pengguna yang bervariasi, dimulai dari 18 hingga 40 tahun. Variasi usia ini menunjukkan bahwa data mencakup berbagai kelompok usia dewasa muda hingga usia tengah, yang mencerminkan beragam demografi dari pengguna yang terlibat. Kedua kolom ini sudah memiliki data yang konsisten tanpa nilai yang hilang, namun untuk analisis lebih lanjut, perlu diperhatikan keseragaman penulisan lokasi.

# Data Preprocessing

## Menangani missing values pada kolom yang akan digunakan
"""

tourism_with_id['Description'] = tourism_with_id['Description'].fillna('')
tourism_with_id['Category'] = tourism_with_id['Category'].fillna('')

"""Kode tersebut digunakan untuk mengisi nilai yang hilang (missing values) pada kolom `Description` dan `Category` di dataframe `tourism_with_id`. Fungsi `fillna('')` menggantikan nilai yang hilang dengan string kosong ('') pada kedua kolom tersebut. Hal ini memastikan tidak ada nilai yang hilang, sehingga dapat mencegah error saat proses analisis atau pemrosesan data lebih lanjut.

## Membuat kolom konten gabungan untuk analisis
"""

tourism_with_id['Content'] = (
    tourism_with_id['Description'] + ' ' + tourism_with_id['Category']
)

"""Kode tersebut membuat kolom baru bernama `Content` pada dataframe `tourism_with_id`. Kolom `Content` diisi dengan menggabungkan (concatenate) nilai dari dua kolom sebelumnya, yaitu `Description` dan `Category`, dengan menambahkan spasi di antara keduanya.

Dengan kata lain, setiap nilai di kolom `Content` akan berisi deskripsi tempat (dari kolom `Description`) diikuti oleh kategori tempat (dari kolom `Category`), yang dipisahkan dengan spasi. Proses ini biasanya digunakan untuk membuat teks yang lebih informatif atau untuk persiapan analisis teks lebih lanjut.

# Model Development

## Content Based Filtering

### TF-IDF Vectorizer untuk mengubah teks menjadi representasi numerik
"""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(tourism_with_id['Content'])

"""Kode ini menggunakan TfidfVectorizer dari library sklearn.feature_extraction.text untuk menghitung matriks TF-IDF (Term Frequency-Inverse Document Frequency) dari kolom Content dalam dataframe tourism_with_id. Matriks ini berisi nilai numerik yang menggambarkan pentingnya kata-kata dalam setiap dokumen relatif terhadap seluruh korpus dokumen yang ada. Semakin tinggi nilai TF-IDF, semakin penting kata tersebut dalam dokumen tertentu.

### Menghitung kesamaan kosinus antara semua destinasi wisata
"""

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""Kode ini menghitung cosine similarity antara setiap pasangan dokumen dalam matriks TF-IDF (tfidf_matrix). Dengan menghitung cosine similarity, kita bisa mengukur seberapa mirip satu tempat wisata dengan tempat wisata lainnya berdasarkan deskripsi dan kategori yang ada dalam data.

### Membuat fungsi untuk rekomendasi berdasarkan nama destinasi
"""

indices = pd.Series(tourism_with_id.index, index=tourism_with_id['Place_Name']).drop_duplicates()

def recommend(place_name, cosine_sim=cosine_sim, df=tourism_with_id):
    if place_name not in indices:
        return "Place not found in the dataset."

    idx = indices[place_name]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]  # Mengambil 5 destinasi paling mirip
    place_indices = [i[0] for i in sim_scores]

    return df.iloc[place_indices][['Place_Name', 'Category', 'Rating']]

"""Fungsi recommend yang Anda buat bertujuan untuk memberikan rekomendasi tempat wisata yang mirip berdasarkan cosine similarity.
Fungsi recommend akan mengembalikan 5 tempat wisata yang paling mirip dengan tempat yang dicari berdasarkan deskripsi dan kategori, beserta nama, kategori, dan rating masing-masing tempat.

### Mendapatkan Rekomendasi
"""

place_to_recommend = "Gembira Loka Zoo"
recommendations = recommend(place_to_recommend)

print(f"Rekomendasi berdasarkan tempat: {place_to_recommend}\n")
print(recommendations)

"""Mencari dan mencetak rekomendasi tempat wisata yang mirip dengan "Gembira Loka Zoo" berdasarkan kesamaan konten deskripsi dan kategori menggunakan recommend yang telah didefinisikan sebelumnya.

## Modelling Dengan Collborative Filtering

### Menggabungkan tourism_rating dengan tourism_with_id
"""

rating_with_details = tourism_rating.merge(
    tourism_with_id[['Place_Id', 'Place_Name', 'Category', 'City']],
    on='Place_Id',
    how='left'
)

"""Bertujuan untuk menggabungkan dua DataFrame, yaitu tourism_rating dan tourism_with_id, berdasarkan kolom Place_Id. Setelah penggabungan, Anda akan mendapatkan DataFrame baru yang berisi informasi dari tourism_rating ditambah dengan nama tempat (Place_Name), kategori (Category), dan kota (City) dari tourism_with_id yang sesuai dengan Place_Id.

### Menambahkan data pengguna ke tourism_rating
"""

rating_with_user = rating_with_details.merge(
    user,
    on='User_Id',
    how='left'
)

"""Bertujuan untuk menggabungkan DataFrame rating_with_details (yang berisi informasi tentang rating tempat wisata beserta detail tempatnya) dengan DataFrame user (yang berisi informasi tentang pengguna, seperti lokasi dan usia) berdasarkan kolom User_Id. Setelah penggabungan, Anda akan mendapatkan DataFrame baru yang berisi informasi rating tempat wisata, detail tempatnya (nama, kategori, kota), serta informasi pengguna (lokasi dan usia) yang memberikan rating tersebut.

### Menambahkan data paket wisata ke destinasi
"""

rating_with_package = rating_with_user.merge(
    package_tourism,
    left_on='Place_Name',
    right_on='Place_Tourism1',
    how='left'
)

"""Bertujuan untuk menggabungkan DataFrame rating_with_user (yang berisi informasi tentang rating tempat wisata, detail tempat wisata, dan informasi pengguna) dengan DataFrame package_tourism (yang berisi informasi tentang paket wisata). Penggabungan dilakukan berdasarkan kecocokan antara kolom Place_Name dari rating_with_user dan kolom Place_Tourism1 dari package_tourism. Setelah penggabungan, Anda akan mendapatkan DataFrame baru (rating_with_package) yang berisi informasi rating tempat wisata, detail tempat wisata, informasi pengguna, serta informasi paket wisata terkait dengan tempat tersebut. Jika ada tempat wisata yang tidak memiliki paket wisata yang sesuai, kolom dari package_tourism akan berisi nilai NaN.

### Hasil dataset gabungan
"""

print(rating_with_package.head())

"""### Membuat pivot table user-item"""

user_item_matrix = rating_with_package.pivot_table(
    index='User_Id',
    columns='Place_Name',
    values='Place_Ratings'
).fillna(0)

"""Kode bertujuan untuk membuat user-item matrix yang menghubungkan pengguna dengan tempat wisata yang mereka beri rating, dan mengisi nilai yang hilang (missing) dengan 0. Ini adalah teknik umum dalam sistem rekomendasi untuk mempersiapkan data sebelum menjalankan algoritma seperti Collaborative Filtering. Setelah kode ini dijalankan, Anda akan memiliki sebuah matriks di mana setiap baris mewakili seorang pengguna dan setiap kolom mewakili sebuah tempat wisata. Nilai di dalam matriks adalah rating yang diberikan oleh pengguna untuk tempat wisata tertentu.

### Menghitung kesamaan antar pengguna
"""

user_similarity = cosine_similarity(user_item_matrix)
user_similarity_df = pd.DataFrame(
    user_similarity,
    index=user_item_matrix.index,
    columns=user_item_matrix.index
)

"""Menghitung similarity antar pengguna menggunakan metode Cosine Similarity dan kemudian menyajikan hasilnya dalam bentuk DataFrame yang mudah dibaca.

### Fungsi untuk merekomendasikan destinasi wisata dengan skor dalam skala 1-5
"""

def recommend_collaborative(user_id, user_item_matrix, user_similarity_df, top_n=5):
    if user_id not in user_item_matrix.index:
        return "User not found in the dataset."

    # Skor prediksi berdasarkan kesamaan pengguna
    similar_users = user_similarity_df[user_id]
    user_ratings = user_item_matrix.T[user_id]
    weighted_sum = user_item_matrix.T.dot(similar_users)
    normalization_factor = np.abs(similar_users).sum()

    # Menghitung skor akhir
    predicted_ratings = weighted_sum / normalization_factor
    predicted_ratings[user_ratings > 0] = 0  # Hindari tempat yang sudah dinilai pengguna

    # Normalisasi skor menjadi skala 1-5
    min_rating, max_rating = 1, 5
    predicted_ratings = ((predicted_ratings - predicted_ratings.min()) /
                         (predicted_ratings.max() - predicted_ratings.min()) *
                         (max_rating - min_rating) + min_rating)

    # Mendapatkan top rekomendasi
    recommended_places = predicted_ratings.sort_values(ascending=False).head(top_n)
    return recommended_places

"""Fungsi recommend_collaborative ini memberikan rekomendasi tempat wisata kepada pengguna berdasarkan Collaborative Filtering dengan mempertimbangkan kesamaan perilaku pengguna lain yang mirip dalam memberikan rating. Algoritma ini berguna ketika kita ingin merekomendasikan tempat-tempat yang mungkin disukai oleh pengguna, berdasarkan preferensi pengguna lain yang memiliki pola rating yang serupa.

### Contoh penggunaan
"""

user_to_recommend = 1
recommendations = recommend_collaborative(user_to_recommend, user_item_matrix, user_similarity_df)

print(f"Rekomendasi untuk User ID {user_to_recommend}:\n")
print(recommendations)

"""Hasil yang diberikan oleh fungsi recommend_collaborative menunjukkan 5 rekomendasi tempat wisata yang sesuai dengan preferensi pengguna dengan User_ID = 1 berdasarkan Collaborative Filtering. Setiap tempat wisata diberi skor prediksi berdasarkan kesamaan rating antara pengguna tersebut dan pengguna lainnya. Tempat-tempat ini adalah yang diprediksi paling disukai oleh pengguna dengan ID 1, berdasarkan kesamaan rating dengan pengguna lainnya. Skor tertinggi 5 menunjukkan bahwa tempat tersebut sangat sesuai dengan preferensi pengguna tersebut, sementara skor lainnya menunjukkan tingkat kecocokan yang sedikit lebih rendah namun tetap cukup tinggi.

# Evaluasi
"""

from sklearn.metrics import mean_squared_error
import numpy as np

# Contoh data: prediksi rating dan rating yang sebenarnya
predicted_ratings = np.array([4.5, 3.0, 5.0, 2.0, 4.8])  # Rating yang diprediksi oleh model
actual_ratings = np.array([5.0, 3.0, 5.0, 1.0, 4.0])  # Rating yang sebenarnya diberikan pengguna

# Precision, Recall, F1-Score (untuk biner relevansi: relevan atau tidak relevan)
def calculate_precision_recall_f1(predicted_ratings, actual_ratings, threshold=3.5):
    # Menentukan relevansi: Rating > threshold dianggap relevan
    predicted_relevance = predicted_ratings >= threshold
    actual_relevance = actual_ratings >= threshold

    tp = np.sum(predicted_relevance & actual_relevance)
    fp = np.sum(predicted_relevance & ~actual_relevance)
    fn = np.sum(~predicted_relevance & actual_relevance)

    # Precision, Recall, dan F1-Score
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return precision, recall, f1_score

# Root Mean Square Error (RMSE)
def calculate_rmse(predicted_ratings, actual_ratings):
    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))
    return rmse

# Menghitung metrik evaluasi
precision, recall, f1_score = calculate_precision_recall_f1(predicted_ratings, actual_ratings)
rmse = calculate_rmse(predicted_ratings, actual_ratings)

print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1_score:.4f}")
print(f"RMSE: {rmse:.4f}")

"""Secara keseluruhan, model ini memiliki kinerja yang sangat baik, dengan prediksi relevansi yang sempurna dan kesalahan prediksi yang relatif rendah, namun masih ada sedikit ruang untuk peningkatan pada prediksi nilai rating."""